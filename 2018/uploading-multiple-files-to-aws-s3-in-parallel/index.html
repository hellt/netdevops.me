<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Uploading multiple files to AWS S3 in parallel |</title><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content><meta name=twitter:title content="Uploading multiple files to AWS S3 in parallel"><meta name=twitter:description content><meta name=twitter:creator content="@ntdvps"><meta name=Description content="DevOps applied to networking"><meta property="og:title" content="Uploading multiple files to AWS S3 in parallel"><meta property="og:description" content="Have you ever tried to upload thousands of small/medium files to the AWS S3? If you had, you might also noticed ridiculously slow upload speeds when the upload was triggered through the AWS Management Console. Recently I tried to upload 4k html files and was immediately discouraged by the progress reported by the AWS Console upload manager. It was something close to the 0.5% per 10s. Clearly, the choke point was the network (as usual, brothers!).
Comer here, Google, we need to find a better way to handle this kind of an upload."><meta property="og:type" content="article"><meta property="og:url" content="https://netdevops.me/2018/uploading-multiple-files-to-aws-s3-in-parallel/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-03-25T12:00:00+00:00"><meta property="article:modified_time" content="2021-04-19T12:35:46+02:00"><meta name=application-name content="NetDevOps"><meta name=apple-mobile-web-app-title content="NetDevOps"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=icon type=image/png sizes=192x192 href=/android-chrome-192x192.png><link rel=icon type=image/png sizes=512x512 href=/android-chrome-512x512.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://netdevops.me/2018/uploading-multiple-files-to-aws-s3-in-parallel/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Uploading multiple files to AWS S3 in parallel","inLanguage":"en-us","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/netdevops.me\/2018\/uploading-multiple-files-to-aws-s3-in-parallel\/"},"genre":"posts","keywords":"AWS","wordCount":871,"url":"https:\/\/netdevops.me\/2018\/uploading-multiple-files-to-aws-s3-in-parallel\/","datePublished":"2018-03-25T12:00:00+00:00","dateModified":"2021-04-19T12:35:46+02:00","description":""}</script></head><body data-header-desktop data-header-mobile><script>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':''==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:''==='dark')&&document.body.setAttribute('theme','dark')</script><div id=mask></div><div class=wrapper><header><div class="desktop header" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=NetDevOps class="header-logo logo-svg">NetDevOps</a></div><div class=menu><nav><h2 class=display-hidden>Основная навигация</h2><ul class=menu-inner><li><a class=menu-item href=/posts/>Posts</a></li><li><a class=menu-item href=/tags/>Tags</a></li></ul></nav><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop><input type=text placeholder=Search... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><span class="svg-icon icon-search"></span></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><span class="svg-icon icon-cancel"></span></a><span class="search-button search-loading" id=search-loading-desktop><span class="svg-icon icon-loading"></span></span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><span class="svg-icon icon-moon"></span></a></div></div></div><div class="mobile header" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=NetDevOps class=header-logo>NetDevOps</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=Search... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><span class="svg-icon icon-search"></span></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><span class="svg-icon icon-cancel"></span></a><span class="search-button search-loading" id=search-loading-mobile><span class="svg-icon icon-loading"></span></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><nav><h2 class=display-hidden>Основная навигация</h2><ul><li><a class=menu-item href=/posts/ title>Posts</a></li><li><a class=menu-item href=/tags/ title>Tags</a></li></ul></nav><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><span class="svg-icon icon-moon"></span></a></div></div></div><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div></header><main class=main><div class="container content-article theme-classic"><div class=toc id=toc-auto><div class=toc-title>Contents</div><div class="toc-content always-active" id=toc-content-auto></div></div><article><header class=header-post><div class=post-title><div class=post-all-meta><nav class=breadcrumbs><ol><li><a href=/>Home</a></li><li>Uploading multiple files to AWS S3 in parallel</li></ol></nav><h1 class="single-title flipInX">Uploading multiple files to AWS S3 in parallel</h1><div class="post-meta summary-post-meta"><span class="post-meta-date meta-item"><span class="svg-icon icon-clock"></span><time class=timeago datetime=2018-03-25>2018-03-25</time>
</span><span class="post-meta-words meta-item"><span class="svg-icon icon-pencil"></span>871 words</span>
<span class="post-meta-reading meta-item"><span class="svg-icon icon-stopwatch"></span>5 minutes</span></div></div></div></header><div class="article-post toc-start"><div class="content-block content-block-first content-block-position"><div class="post single"><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><ul><li><a href=#1-aws-management-console>1. AWS Management Console</a></li><li><a href=#2-aws-s3-sync>2. aws s3 sync</a></li><li><a href=#3-aws-s3-cp-with-xargs>3. aws s3 cp with xargs</a></li><li><a href=#4-aws-s3-cp-with-parallel>4. aws s3 cp with parallel</a></li><li><a href=#5-what-if-i-had-some-more-cpu-cores>5. What if I had some more CPU cores?</a></li></ul></li></ul></nav></div></div><div style="margin:20px 0"><span class=post-update><span class=s>Updated on 2021-04-19</span></span></div><p>Have you ever tried to upload thousands of small/medium files to the AWS S3? If you had, you might also noticed ridiculously slow upload speeds when the upload was triggered through the AWS Management Console. Recently I tried to upload 4k html files and was immediately discouraged by the progress reported by the AWS Console upload manager. It was something close to the 0.5% per 10s. Clearly, the choke point was the network (as usual, brothers!).</p><p>Comer here, Google, we need to find a better way to handle this kind of an upload.</p><p>To set a context, take a look at the file size distribution I had (thanks to this <a href=https://superuser.com/questions/565443/generate-distribution-of-file-sizes-from-the-command-prompt target=_blank rel="noopener noreffer">awk magic</a>):</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>  Size, KB   Num of files
       256   2
       512   2
      1024   8
      2048 1699
      4096 1680
      8192 579
     16384 323
     32768 138
     65536  34
    131072   6
    262144   1
   1048576   1
   2097152   1
   4194304   1
</code></pre></td></tr></table></div></div><p>My thought was that maybe there is a way to upload a tar.gz archive and unpack it in an S3 bucket, unfortunately this is not supported by the S3. The remaining options were (<a href=https://stackoverflow.com/questions/28291466/how-to-extract-files-from-a-zip-archive-in-s3 target=_blank rel="noopener noreffer">as per this SO thread</a>):</p><blockquote><ol><li>You could mount the S3 bucket as a local filesystem using s3fs and FUSE (see article and github site). This still requires the files to be downloaded and uploaded, but it hides these operations away behind a filesystem interface.</li></ol></blockquote><blockquote><ol start=2><li>If your main concern is to avoid downloading data out of AWS to your local machine, then of course you could download the data onto a remote EC2 instance and do the work there, with or without s3fs. This keeps the data within Amazon data centers.</li></ol></blockquote><blockquote><ol start=3><li>You may be able to perform remote operations on the files, without downloading them onto your local machine, using AWS Lambda.</li></ol></blockquote><p>Hands down, these three methods could give you the best speeds, since you could upload tar archive and do the heavy lifting on the AWS side. But none of them were quite appealing to me considering the one-time upload I needed to handle. I hoped to find kind of a parallel way of the multiple uploads with a CLI approach.</p><p>So what I found boiled down to the following CLI-based workflows:</p><ol><li><code>aws s3 rsync</code> command</li><li><code>aws cp</code> command with <code>xargs</code> to act on multiple files</li><li><code>aws cp</code> command with <code>parallel</code> to act on multiple files</li></ol><p>TL;DR: First option won the competition (# of cores matters), but lets have a look at the numbers. I created 100 files 4096B each and an empty test bucket to do the tests:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=c1># create 100 files size of 4096 bytes each</span>
seq -w <span class=m>1</span> <span class=m>100</span> <span class=p>|</span> xargs -n1 -I% sh -c <span class=s1>&#39;dd if=/dev/urandom of=file.% bs=1 count=4096&#39;</span>
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash>$ find . -type f -print0 <span class=p>|</span> xargs -0 ls -l <span class=p>|</span> awk <span class=s1>&#39;{size[int(log($5)/log(2))]++}END{for (i in size) printf(&#34;%10d %3d\n&#34;, 2^i, size[i])}&#39;</span> <span class=p>|</span> sort -n

      <span class=m>4096</span> <span class=m>100</span>
</code></pre></td></tr></table></div></div><h3 id=1-aws-management-console class=headerLink><a href=#1-aws-management-console class=header-mark></a>1. AWS Management Console</h3><p>As a normal human being I selected all these 100 files in the file dialog of the AWS Management Console and waited for <strong>5 minutes</strong> to upload 100 of them. Horrible.</p><blockquote><p>The rest of the tests were run on an old 2012 MacBook Air with 4vCPUs.</p></blockquote><h3 id=2-aws-s3-sync class=headerLink><a href=#2-aws-s3-sync class=header-mark></a>2. aws s3 sync</h3><p>A <code>aws s3 sync</code> command is cool when you only want to upload the missing files or make the remote part in sync with a local one. In case when a bucket is empty a sequential upload will happen, but will it be fast enough?</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-bash data-lang=bash><span class=nb>time</span> aws s3 sync . s3://test-ntdvps

real	0m10.124s
user	0m1.470s
sys	0m0.273s
</code></pre></td></tr></table></div></div><p>10 seconds! Not bad at all!</p><h3 id=3-aws-s3-cp-with-xargs class=headerLink><a href=#3-aws-s3-cp-with-xargs class=header-mark></a>3. aws s3 cp with xargs</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>ls -1 | time xargs -I % aws s3 cp % s3://test-ntdvps
294.05 real        68.76 user         9.27 sys
</code></pre></td></tr></table></div></div><p>5 mins! As bad as the AWS Management Console way!</p><h3 id=4-aws-s3-cp-with-parallel class=headerLink><a href=#4-aws-s3-cp-with-parallel class=header-mark></a>4. aws s3 cp with parallel</h3><p><code>parallel</code> is a <a href=https://www.gnu.org/software/parallel/parallel_tutorial.html target=_blank rel="noopener noreffer">GNU tool to run parallel shell commands</a>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback># parallel with 60 workers
ls -1 | time parallel -j60 -I % aws s3 cp % s3://test-ntdvps --profile rdodin-cnpi
39.32 real       108.41 user        14.46 sys
</code></pre></td></tr></table></div></div><p>~40 seconds, better than <code>xargs</code> and worse than <code>aws s3 sync</code>. With an increasing number of the files <code>aws s3 sync</code> starts to win more, and the reason is probably because <code>aws s3 sync</code> uses one tcp connection, while <code>aws s3 cp</code> opens a new connection for an each file transfer operation.</p><h3 id=5-what-if-i-had-some-more-cpu-cores class=headerLink><a href=#5-what-if-i-had-some-more-cpu-cores class=header-mark></a>5. What if I had some more CPU cores?</h3><p>You can increase the number of the workers, and if you have a solid amount of threads available you might win the upload competition:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback># 48 Xeon vCPUs, same 100 files 4KB each

aws s3 sync: 6.5 seconds
aws s3 cp with parallel and 128 jobs: 4.5 seconds

# now 1000 files 4KB each
aws s3 sync: 40 seconds
aws s3 cp with parallel and 252 jobs: 21.5 seconds
</code></pre></td></tr></table></div></div><p>So you see that the <code>aws s3 cp</code> with <code>parallel</code> might come handy if you have enough of vCPUs to handle that many parallel workers. But if you are sending your files from a regular notebook/PC the <code>aws s3 sync</code> command will usually be of a better choice.</p></div><footer><div class=post><div class=post-share><div class=share-link><a class="share-icon share-twitter" href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://netdevops.me/2018/uploading-multiple-files-to-aws-s3-in-parallel/ data-title="Uploading multiple files to AWS S3 in parallel" data-via=ntdvps data-hashtags=AWS><span class="svg-social-icon icon-twitter"></span></a></div><div class=share-link><a class="share-icon share-facebook" href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://netdevops.me/2018/uploading-multiple-files-to-aws-s3-in-parallel/ data-hashtag=AWS><span class="svg-social-icon icon-facebook"></span></a></div><div class=share-link><a class="share-icon share-linkedin" href=javascript:void(0); title="Share on Linkedin" data-sharer=linkedin data-url=https://netdevops.me/2018/uploading-multiple-files-to-aws-s3-in-parallel/><span class="svg-social-icon icon-linkedin"></span></a></div></div><div class=post-tags><a href=/tags/aws/ class=tag>AWS</a></div></div></footer></div><div id=toc-final></div></div></article><section class="page single comments content-block-position"><h1 class=display-hidden>Комментарии</h1><div id=comments><div id=utterances></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://utteranc.es/>Utterances</a>.</noscript></div></section></div></main><footer class=footer><div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.82.0">Hugo</a> | Theme - <a href="https://ublogger.netlify.app/?utm_source=https://netdevops.me/&utm_medium=footer&utm_campaign=config&utm_term=2.0.1" target=_blank title="uBlogger 2.0.1">uBlogger</a></div><div class=footer-line><i class="svg-icon icon-copyright"></i><span>2015 - 2021</span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><aside id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="svg-icon icon-arrow-up"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="svg-icon icon-comments-fixed"></i></a></aside><link rel=stylesheet href=/drawio.css><script src=/lib/smooth-scroll/smooth-scroll.min.js></script><script src=/lib/autocomplete/autocomplete.min.js></script><script src=/lib/algoliasearch/algoliasearch-lite.umd.min.js></script><script src=/lib/clipboard/clipboard.min.js></script><script src=/lib/sharer/sharer.min.js></script><script>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:20},comment:{utterances:{darkTheme:"github-dark",issueTerm:"pathname",label:"comment",lightTheme:"github-light",repo:"hellt/netdevops.me"}},search:{algoliaAppID:"H1AI8QKFEK",algoliaIndex:"blog",algoliaSearchKey:"0544bc3c928ba0e387c3b3353112e43d",highlightTag:"em",maxResultLength:10,noResultsFound:"No results found",snippetLength:60,type:"algolia"}}</script><script src=/js/theme.min.js></script><script>(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-101537614-1','auto'),ga('send','pageview')</script></body></html>